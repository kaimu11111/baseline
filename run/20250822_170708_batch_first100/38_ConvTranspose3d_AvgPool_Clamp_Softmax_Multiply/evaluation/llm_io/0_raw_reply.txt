```python
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# Custom CUDA source code combining clamp and softmax+scale kernels
source = r'''
#include <torch/extension.h>
#include <cuda_runtime.h>
#include <float.h>

// Simple block-wise reduction for max
__device__ float blockReduceMax(float val) {
    extern __shared__ float sdata[];
    int tid = threadIdx.x;
    sdata[tid] = val;
    __syncthreads();

    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {
        if (tid < stride) {
            float other = sdata[tid + stride];
            if (other > sdata[tid]) {
                sdata[tid] = other;
            }
        }
        __syncthreads();
    }
    return sdata[0];
}

// Simple block-wise reduction for sum
__device__ float blockReduceSum(float val) {
    extern __shared__ float sdata[];
    int tid = threadIdx.x;
    sdata[tid] = val;
    __syncthreads();

    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {
        if (tid < stride) {
            sdata[tid] += sdata[tid + stride];
        }
        __syncthreads();
    }
    return sdata[0];
}

// Kernel to clamp values in x to [min_val, max_val]
__global__ void clamp_kernel(const float* __restrict__ in,
                             float* __restrict__ out,
                             float min_val,
                             float max_val,
                             const long long N) {
    long long idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < N){
        float val = in[idx];
        val = (val < min_val) ? min_val : val;
        val = (val > max_val) ? max_val : val;
        out[idx] = val;
    }
}

// Kernel to compute softmax along the last dimension (rowLen) of a (B*C) x rowLen flattened input,
// and then multiply by a per-channel scale (scale[c]).
__global__ void softmax_scale_kernel(const float* __restrict__ in,
                                     float* __restrict__ out,
                                     const float* __restrict__ scale,
                                     const int B,
                                     const int C,
                                     const int rowLen) {
    int rowIdx = blockIdx.x;  // each block handles one (b,c) row
    if (rowIdx >= B*C) return;

    int b = rowIdx / C;
    int c = rowIdx % C;

    // offset into flattened array
    long long offset = (long long)rowIdx * rowLen;

    // 1) find max
    float threadMax = -FLT_MAX;
    for (int i = threadIdx.x; i < rowLen; i += blockDim.x) {
        float val = in[offset + i];
        threadMax = (val > threadMax) ? val : threadMax;
    }
    // reduce max within the block
    float maxVal = blockReduceMax(threadMax);
    __shared__ float smax[1];
    if (threadIdx.x == 0) {
        smax[0] = maxVal;
    }
    __syncthreads();
    maxVal = smax[0];

    // 2) compute sum of exponentials
    float threadSum = 0.0f;
    for (int i = threadIdx.x; i < rowLen; i += blockDim.x) {
        float val = expf(in[offset + i] - maxVal);
        threadSum += val;
    }
    float sumExp = blockReduceSum(threadSum);
    __shared__ float sSumExp[1];
    if (threadIdx.x == 0) {
        sSumExp[0] = sumExp;
    }
    __syncthreads();
    sumExp = sSumExp[0];

    float scaleVal = scale[c];

    // 3) normalize and multiply by scale
    for (int i = threadIdx.x; i < rowLen; i += blockDim.x) {
        float val = expf(in[offset + i] - maxVal) / sumExp;
        out[offset + i] = val * scaleVal;
    }
}

// -----------------------------------------------------------------------------

torch::Tensor clamp_cuda(torch::Tensor x, float min_val, float max_val) {
    auto out = torch::empty_like(x);
    long long N = x.numel();

    const int block_size = 256;
    const long long num_blocks = (N + block_size - 1) / block_size;

    clamp_kernel<<<num_blocks, block_size>>>(x.data_ptr<float>(),
                                            out.data_ptr<float>(),
                                            min_val,
                                            max_val,
                                            N);
    return out;
}

torch::Tensor softmax_scale_cuda(torch::Tensor x, torch::Tensor scale, int B, int C) {
    // x is (B, C, rowLen) flattened to 3D but stored as 2D shape: (B*C, rowLen).
    // scale is shape [C], already flattened.
    auto out = torch::empty_like(x);

    int rowLen = x.size(2);  // after view(..., -1) => x.shape = [B, C, rowLen]

    const int block_size = 256;
    const int grid_size = B*C;

    // Launch kernel
    softmax_scale_kernel<<<grid_size, block_size, block_size * sizeof(float)>>>(
        x.data_ptr<float>(),
        out.data_ptr<float>(),
        scale.data_ptr<float>(),
        B, C, rowLen
    );

    return out;
}
''';

# Declarations for the clamp and softmax+scale functions
cpp_src = r'''
torch::Tensor clamp_cuda(torch::Tensor x, float min_val, float max_val);
torch::Tensor softmax_scale_cuda(torch::Tensor x, torch::Tensor scale, int B, int C);
'''

# Load/compile the custom CUDA extension
opt_kernels = load_inline(
    name="opt_kernels",
    cpp_sources=cpp_src,
    cuda_sources=source,
    functions=["clamp_cuda", "softmax_scale_cuda"],
    verbose=False
)

class ModelNew(nn.Module):
    """
    Optimized Model with custom CUDA kernels for clamping and softmax+scale.
    """
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding,
                 pool_kernel_size, clamp_min, clamp_max):
        super(ModelNew, self).__init__()
        self.avg_pool = nn.AvgPool3d(pool_kernel_size)
        self.conv_transpose = nn.ConvTranspose3d(
            in_channels, out_channels, kernel_size,
            stride=stride, padding=padding, output_padding=output_padding
        )
        self.clamp_min = clamp_min
        self.clamp_max = clamp_max
        self.scale = nn.Parameter(torch.ones(1, out_channels, 1, 1, 1))

    def forward(self, x):
        x = self.avg_pool(x)
        x = self.conv_transpose(x)
        # Use custom CUDA clamp
        x = opt_kernels.clamp_cuda(x, self.clamp_min, self.clamp_max)
        # Flatten (b,c,d,h,w) -> (b,c,d*h*w)
        b, c, d, h, w = x.shape
        x = x.view(b, c, -1)
        # Use custom CUDA softmax+scale
        # Flatten scale to [c] because scale is [1,c,1,1,1]
        x = opt_kernels.softmax_scale_cuda(x, self.scale.view(-1), b, c)
        # Reshape back
        x = x.view(b, c, d, h, w)
        return x

# Same input getters, for completeness
def get_inputs():
    batch_size = 32
    in_channels = 32
    depth, height, width = 32, 64, 64
    return [torch.rand(batch_size, in_channels, depth, height, width).cuda()]

def get_init_inputs():
    batch_size = 32
    in_channels = 32
    out_channels = 64
    depth, height, width = 32, 64, 64
    kernel_size = 3
    stride = 2
    padding = 1
    output_padding = 1
    pool_kernel_size = 2
    clamp_min = 0.0
    clamp_max = 1.0
    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, clamp_min, clamp_max]
```