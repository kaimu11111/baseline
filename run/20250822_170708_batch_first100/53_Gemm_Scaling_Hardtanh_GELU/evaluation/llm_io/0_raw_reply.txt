```python
import math
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

batch_size = 2048
in_features = 8192
out_features = 8192
scaling_factor = 0.5
hardtanh_min = -2.0
hardtanh_max = 2.0

# Inline CUDA/C++ source code for a naive GEMM + fused scale+hardtanh+GELU
source = r"""
#include <torch/extension.h>
#include <cuda_runtime.h>
#include <math.h>

// Naive GEMM kernel: out = x * w^T + b
// x: [batch_size, in_features]
// w: [out_features, in_features]
// b: [out_features]
// out: [batch_size, out_features]
__global__ void gemm_naive_kernel(const float* __restrict__ x,
                                  const float* __restrict__ w,
                                  const float* __restrict__ b,
                                  float* __restrict__ out,
                                  const int batch_size,
                                  const int in_features,
                                  const int out_features) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < batch_size * out_features) {
        int row = idx / out_features;  // which batch
        int col = idx % out_features;  // which output feature
        float val = 0.0f;
        // compute dot product
        for (int k = 0; k < in_features; k++) {
            val += x[row * in_features + k] * w[col * in_features + k];
        }
        // add bias
        val += b[col];
        out[idx] = val;
    }
}

// Fused scale + hardtanh + GELU kernel
__global__ void fused_activation_kernel(float* __restrict__ data,
                                        const float scale,
                                        const float min_val,
                                        const float max_val,
                                        const int size) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        float val = data[idx];
        // scale
        val = val * scale;
        // clamp
        val = fmaxf(val, min_val);
        val = fminf(val, max_val);
        // GELU (using erf)
        float c = 1.41421356237f; // approximate sqrt(2)
        val = 0.5f * val * (1.0f + erff(val / c));
        data[idx] = val;
    }
}

// A single entry point that performs GEMM + fused scale+hardtanh+GELU:
torch::Tensor fused_forward_cuda(torch::Tensor x,
                                 torch::Tensor w,
                                 torch::Tensor b,
                                 float scale,
                                 float min_val,
                                 float max_val) {
    // x shape: [batch_size, in_features]
    // w shape: [out_features, in_features]
    // b shape: [out_features]
    TORCH_CHECK(x.is_cuda(), "x must be CUDA tensor");
    TORCH_CHECK(w.is_cuda(), "w must be CUDA tensor");
    TORCH_CHECK(b.is_cuda(), "b must be CUDA tensor");
    TORCH_CHECK(x.dim() == 2, "x must be 2D");
    TORCH_CHECK(w.dim() == 2, "w must be 2D");
    TORCH_CHECK(b.dim() == 1, "b must be 1D");

    const int batch_size = x.size(0);
    const int in_features = x.size(1);
    const int out_features = w.size(0);

    auto options = x.options();
    auto out = torch::empty({batch_size, out_features}, options);

    // Naive GEMM
    int total_threads = batch_size * out_features;
    int block_size = 256;
    int grid_size = (total_threads + block_size - 1) / block_size;

    gemm_naive_kernel<<<grid_size, block_size>>>(
        x.data_ptr<float>(),
        w.data_ptr<float>(),
        b.data_ptr<float>(),
        out.data_ptr<float>(),
        batch_size,
        in_features,
        out_features
    );

    // Fused scale + hardtanh + GELU
    fused_activation_kernel<<<grid_size, block_size>>>(
        out.data_ptr<float>(),
        scale,
        min_val,
        max_val,
        total_threads
    );

    return out;
}
""".strip()

# C++ declarations to expose the fused_forward_cuda function
cpp_src = r"""
torch::Tensor fused_forward_cuda(torch::Tensor x,
                                 torch::Tensor w,
                                 torch::Tensor b,
                                 float scale,
                                 float min_val,
                                 float max_val);
"""

# Build the fused custom extension
fused_module = load_inline(
    name="fused_gemm_activations",
    cpp_sources=cpp_src,
    cuda_sources=source,
    functions=["fused_forward_cuda"],
    verbose=False,
)

class ModelNew(nn.Module):
    """
    Optimized model that uses a custom naive GEMM followed by a fused
    scale + hardtanh + GELU in a single CUDA extension.
    """
    def __init__(self, in_features, out_features, scaling_factor, hardtanh_min, hardtanh_max):
        super(ModelNew, self).__init__()
        # Store weights/bias as parameters to replicate nn.Linear
        self.weight = nn.Parameter(torch.empty(out_features, in_features))
        self.bias = nn.Parameter(torch.empty(out_features))
        nn.init.xavier_uniform_(self.weight)
        nn.init.zeros_(self.bias)

        self.scaling_factor = scaling_factor
        self.hardtanh_min = hardtanh_min
        self.hardtanh_max = hardtanh_max

    def forward(self, x):
        return fused_module.fused_forward_cuda(
            x,
            self.weight,
            self.bias,
            self.scaling_factor,
            self.hardtanh_min,
            self.hardtanh_max
        )

def get_inputs():
    return [torch.rand(batch_size, in_features, device="cuda")]

def get_init_inputs():
    return [in_features, out_features, scaling_factor, hardtanh_min, hardtanh_max]
```