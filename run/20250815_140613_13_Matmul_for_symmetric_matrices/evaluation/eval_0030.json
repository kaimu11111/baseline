{
  "runnable": false,
  "phase": "seed",
  "error_type": "CompilationError",
  "message": "Using /home/wan00559/.cache/torch_extensions/py311_cu126 as PyTorch extensions root...\nDetected CUDA files, patching ldflags\nEmitting ninja build file /home/wan00559/.cache/torch_extensions/py311_cu126/matmul_cuda/build.ninja...\n/home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \nIf this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n  warnings.warn(\nBuilding extension module matmul_cuda...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n[1/3] /usr/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -DTORCH_EXTENSION_NAME=matmul_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/wan00559/miniconda3/envs/maxk/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -std=c++17 -c /home/wan00559/.cache/torch_extensions/py311_cu126/matmul_cuda/cuda.cu -o cuda.cuda.o \nFAILED: cuda.cuda.o \n/usr/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -DTORCH_EXTENSION_NAME=matmul_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/wan00559/miniconda3/envs/maxk/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -std=c++17 -c /home/wan00559/.cache/torch_extensions/py311_cu126/matmul_cuda/cuda.cu -o cuda.cuda.o \n/home/wan00559/.cache/torch_extensions/py311_cu126/matmul_cuda/cuda.cu:62:67: error: macro \"assert\" passed 2 arguments, but takes just 1\n   62 |     assert(A.dim() == 2 && A.size(0) == A.size(1), \"A must be NxN\");\n      |                                                                   ^\nIn file included from /usr/include/c++/12/cassert:44,\n                 from /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include/pybind11/gil_safe_call_once.h:8,\n                 from /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include/pybind11/pybind11.h:17,\n                 from /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include/torch/csrc/Exceptions.h:12,\n                 from /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/python.h:11,\n                 from /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include/torch/extension.h:9,\n                 from /home/wan00559/.cache/torch_extensions/py311_cu126/matmul_cuda/cuda.cu:5:\n/usr/include/assert.h:102: note: macro \"assert\" defined here\n  102 | #  define assert(expr)                                                  \\\n      | \n/home/wan00559/.cache/torch_extensions/py311_cu126/matmul_cuda/cuda.cu:63:67: error: macro \"assert\" passed 2 arguments, but takes just 1\n   63 |     assert(B.dim() == 2 && B.size(0) == B.size(1), \"B must be NxN\");\n      |                                                                   ^\n/usr/include/assert.h:102: note: macro \"assert\" defined here\n  102 | #  define assert(expr)                                                  \\\n      | \n/home/wan00559/.cache/torch_extensions/py311_cu126/matmul_cuda/cuda.cu:64:63: error: macro \"assert\" passed 2 arguments, but takes just 1\n   64 |     assert(A.size(0) == B.size(0), \"A and B must be same size\");\n      |                                                               ^\n/usr/include/assert.h:102: note: macro \"assert\" defined here\n  102 | #  define assert(expr)                                                  \\\n      | \n[2/3] c++ -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=matmul_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/wan00559/miniconda3/envs/maxk/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -c /home/wan00559/.cache/torch_extensions/py311_cu126/matmul_cuda/main.cpp -o main.o \nninja: build stopped: subcommand failed.\nError building extension 'matmul_cuda'"
}